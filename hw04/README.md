# hw4

## Требования

Перед запуском скрипта необходимы работающие `HDFS`, `YARN` и `HiveServer2`

Предварительно в `hdfs` был загружен файл `yellow_tripdata_2025_09.parquet` командой, взятый [отсюда](https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2025-09.parquet)

```shell
hdfs dfs -put yellow_tripdata_2025_09.parquet /input
```

Для корректной работы должны быть установлены `python3`, `python3-pip` и `python3-venv`

## Запуск

Основной скрипт для запуска Spark - scripts/run_spark.sh

### Запуск Hive Metastore

### Настройка Python

- Создается виртуальное `venv` окружение
- Активируется окружение по имени `.venv`
- `pip` обновляется до последней версии
- Устанавливаются зависимости из `requirements.txt`

### Запуск Python

- Запускается сессия `Spark` под управлением `YARN`
- Создается подключение к кластеру `HDFS`
- Сессия `Spark` читает данные из `HDFS`
- Производятся трансформации данных
    1. Добавляем новый столбец - среднее общее число пассажиров во всех поездках
    2. Складывает значения из двух столбцов passenger_count, trip_distancep pass_count_trip_dist
    3. Изменяет тип на int колонки passenger_count
    4. Получаем новый столбец - длительность поездки как разницу tpep_dropoff_datetime и tpep_pickup_datetime
    5. Группирует по passenger_count и вычисляет среднее для каждой группы
- Результат сохраняется как таблица, партиционированная по колонке `VendorID`
- Убедиться, что стандартный клиент hive может прочитать данные.
- Для повышения оценки: применить 5 трансформаций разных видов, сохранить данные как партиционированную таблицу.

### Результат

Чтобы проверить результат запуска скрипта, необходимо пробрасить порты:

```shell
ssh -L 10002:192.168.1.95:10002 -L 9870:192.168.1.95:9870 -L 8088:192.168.1.95:8088 -L 19888:192.168.1.95:19888 team@176.109.91.25
```

Станут доступны следующие сервисы:

- [NameNode](localhost:9870)
- [ResourceManager](localhost:8088)
- [JobHistoryServer](localhost:19888)
- [HiveServer2](localhost:10002)
